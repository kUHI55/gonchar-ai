import OpenAI from "openai";
import { NextResponse } from "next/server";

export const runtime = "nodejs";


let lastRequestTime = 0;

function isRegionBlock(err) {
  const status = err?.status || err?.response?.status;
  const msg = String(err?.message || "");

  return (
    status === 403 ||
    msg.includes("Country, region, or territory not supported") ||
    msg.toLowerCase().includes("region") ||
    msg.toLowerCase().includes("territory")
  );
}


function extractJsonObject(text) {
  const s = String(text || "").trim();
  const first = s.indexOf("{");
  const last = s.lastIndexOf("}");
  if (first === -1 || last === -1 || last <= first) return null;
  return s.slice(first, last + 1);
}

export async function POST(req) {
  try {
    const now = Date.now();
    if (now - lastRequestTime < 3000) {
      return NextResponse.json(
        { error: "ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸ 3 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð¿ÐµÑ€ÐµÐ´ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð¼ ðŸ™‚" },
        { status: 429 }
      );
    }
    lastRequestTime = now;

    const { topic } = await req.json();

    if (!topic || !topic.trim()) {
      return NextResponse.json({ error: "Topic is required" }, { status: 400 });
    }

    const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

    
    const model = process.env.OPENAI_MODEL || "gpt-4.1-mini";

    const system = `
Ð¢Ñ‹ â€” ÑˆÐºÐ¾Ð»ÑŒÐ½Ñ‹Ð¹ AI-Ñ€ÐµÐ¿ÐµÑ‚Ð¸Ñ‚Ð¾Ñ€ Ð¿Ð¾ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐµ Ð´Ð»Ñ ÑƒÑ‡ÐµÐ½Ð¸ÐºÐ° 10â€“16 Ð»ÐµÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¹ JSON. ÐÐ¸ÐºÐ°ÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð²Ð¾ÐºÑ€ÑƒÐ³. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… code fences.

Ð’ÐÐ–ÐÐž ÐŸÐ Ðž Ð¤ÐžÐ ÐœÐ£Ð›Ð«:
- ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ LaTeX: Ð½Ð¸ÐºÐ°ÐºÐ¸Ñ… $...$, $$...$$, \\frac, \\sqrt Ð¸ Ñ‚.Ð¿.
- Ð¤Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹ Ð¿Ð¸ÑˆÐ¸ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼: "x^2 - 5x + 6 = 0", "D = b^2 - 4ac", "x = (-b Â± sqrt(D)) / (2a)".
`.trim();

    const user = `
Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ ÑƒÑ€Ð¾Ðº Ð´Ð»Ñ Ñ€ÐµÐ±Ñ‘Ð½ÐºÐ° Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ: "${topic}".

Ð’ÐµÑ€Ð½Ð¸ Ð¡Ð¢Ð ÐžÐ“Ðž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:

{
  "title": "Ð¢ÐµÐ¼Ð°: ...",
  "theory": "markdown-Ñ‚ÐµÐºÑÑ‚ (Ð±ÐµÐ· LaTeX)",
  "tasks": [
    { "id": "t1", "title": "Ð—Ð°Ð´Ð°Ñ‡Ð° 1", "prompt": "..." },
    { "id": "t2", "title": "Ð—Ð°Ð´Ð°Ñ‡Ð° 2", "prompt": "..." },
    { "id": "t3", "title": "Ð—Ð°Ð´Ð°Ñ‡Ð° 3", "prompt": "..." }
  ]
}

ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ðº Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼:
- 3 Ð·Ð°Ð´Ð°Ñ‡Ð¸, Ð¾Ñ‚ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ðº ÑÐ»Ð¾Ð¶Ð½ÐµÐµ
- Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ Ð¸ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ðµ
- Ð±ÐµÐ· LaTeX
`.trim();

    const response = await client.responses.create({
      model,
      input: [
        { role: "system", content: system },
        { role: "user", content: user },
      ],
      max_output_tokens: 1200,
    });

    const raw = response.output_text?.trim() || "";

    
    let data = null;
    try {
      data = JSON.parse(raw);
    } catch {
      
      const cut = extractJsonObject(raw);
      if (!cut) {
        return NextResponse.json(
          { error: "Model returned invalid JSON", raw },
          { status: 500 }
        );
      }
      try {
        data = JSON.parse(cut);
      } catch {
        return NextResponse.json(
          { error: "Model returned invalid JSON", raw },
          { status: 500 }
        );
      }
    }

    
    if (!data?.title || !data?.theory || !Array.isArray(data?.tasks)) {
      return NextResponse.json(
        { error: "JSON schema mismatch", raw, parsed: data },
        { status: 500 }
      );
    }

    return NextResponse.json(data);
  } catch (err) {
    if (isRegionBlock(err)) {
      return NextResponse.json(
        {
          code: "REGION_BLOCK",
          error:
            "OpenAI API Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ Ð¸Ð·-Ð·Ð° Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°/VPN. ÐÐ° Vercel Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚. Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ â€” Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ð»Ð¾Ð³Ð¸ Ð´ÐµÐ¿Ð»Ð¾Ñ.",
        },
        { status: 200 }
      );
    }

    return NextResponse.json(
      { error: err?.message || "Server error" },
      { status: 500 }
    );
  }
}
